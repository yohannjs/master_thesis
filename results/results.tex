\chapter{Results}

In this chapter the results will be presented in the form of three case studies. 
Each case study will focus on a single target variable, and aims to find which model group performs best at predicting the target variable in question.
Recall that the three target variables that will be considered in this thesis are: Heart failure, patient diagnosis, and the indication of individual left ventricle segments.
As mentioned earlier in the chapter, four model groups will be tested. 
The case studies will first deal with each model group individually, where variants of the models with different hypermarameters will be tested on the different datasets. 
Then, the best performing model within each model group will be used to compare the four model groups.

\section{Case Study: Heart Failure}

\subsection{Time-series Clustering}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc_hf_dor_sens_spec_dist.png}
    \input{results/tsc_hf_dor_sens_spec_dist.pgf}
    \caption{(a) Distribution plot of DOR of all TSC methods evaluated at two cluster centers when applied to classify heart failure.
             (b) Scatter plot of the same methods sensitivity-, and specificity-scores.}
    \label{fig:tsc_hf_dor_sens_spec_dist}
\end{figure}

Figure \ref{fig:tsc_hf_dor_sens_spec_dist}a shows that the DOR is rounded down to zero for all the two-cluster-center methods, meaning that the ratio of $TP \times TN$ is small compared to $FP \times FN$. 
From the scatterplot in figure \ref{fig:tsc_hf_dor_sens_spec_dist}b one can see that the distribution of sensitivity, and specificity are quite widespread.
Some sensitivity scores are as high as 1, and some specificity scores as high as high as $0.90$
However, from the scatterplot one can also ascertain that the methods that score above zero in sensitivity score zero in specificity, and vice versa. 
This observation explains why the DOR is zero for all the TSC methods evaluated at two cluster centers, 
and means that the TSC methods evaluated at two cluster centers do not perform well at identifying heart failure among patients. \bigskip

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc_hf_ari.png}
    \input{results/tsc_hf_ari.pgf}
    \caption{Distribution plot of ARI of all TSC methods evaluated at $\{2,9\}$ cluster centers when applied to classify heart failure.}
    \label{fig:tsc_hf_ari}
\end{figure}

\begin{table*}[htb]
    \centering
    \ra{1.3}
    \begin{tabular}{lr}
        \toprule
        Dataset-Method             &  ARI \\
        \midrule
        gls/2CH/regular/centroid/2 & 0.25 \\
        gls/2CH/scaled/centroid/2  & 0.25 \\
        gls/2CH/scaled/centroid/3  & 0.24 \\
        gls/2CH/regular/centroid/3 & 0.24 \\
        gls/2CH/scaled/average/2   & 0.24 \\
        \bottomrule
    \end{tabular}
    \caption{The five highest ARI scores attained when applying TSC for detecting heart failure.
             The \textbf{Dataset-Method} column indicates \textit{Dataset used}$/$\textit{View used}$/$\textit{Linkage criteria of method}$/$\textit{Number of cluster centers}.}
    \label{tab:tsc_hf_ari}
\end{table*}

As mentioned in section REFERENCE DOR, sensitivity and specificity are only well defined for clustering methods evaluated at two cluster centers,
so to determine whether the same clustering methods evaluated at a different number of cluster centers the ARI is used.
From figure \ref{fig:tsc_hf_ari} one can see that the majority of the ARIs of all TSC methods and patient heart failure diagnosis are located close to zero, 
indicating that these cluster assignments have little correlation with heart failure. 
There are a few ARIs that are $0.25$, but from inspection of table \ref{tab:tsc_hf_ari} one can see that they belong to cluster methods evaluated at two cluster centers, 
which have already been shown to have a low performance at predicting heart failure.
So overall, TSC does not perform well at detecting heart failure. \bigskip
\newpage

\subsection{Peak-value Clustering}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvc_hf_dor_sens_spec_dist.png}
    \input{results/pvc_hf_dor_sens_spec_dist.pgf}
    \caption{(a) Distribution plot of DOR of all PVC methods evaluated at two cluster centers when applied to classify heart failure.
             (b) Scatter plot of the same methods sensitivity-, and specificity-scores.}
    \label{fig:pvc_hf_dor_sens_spec_dist}
\end{figure}

\begin{table*}[htb]
    \centering
    \ra{1.3}
    \begin{tabular}{p{3.5cm}p{1.5cm}p{1.65cm}p{1.65cm}p{1cm}}
        \toprule
        Dataset-Method    &  Accuracy &  Sensitivity &  Specificity &   DOR \\
        \midrule
        gls-EF/ward/2     &      0.75 &         0.87 &         0.63 & 11.59 \\
        gls-EF/complete/2 &      0.76 &         0.81 &         0.72 & 10.85 \\
        gls-EF/average/2  &      0.75 &         0.85 &         0.65 & 10.58 \\
        rls-EF/complete/2 &      0.73 &         0.86 &         0.60 &  8.89 \\
        gls-rls-EF/ward/2 &      0.72 &         0.84 &         0.60 &  7.80 \\
        \bottomrule
    \end{tabular}
    \caption{The accuracy, DOR, sensitivity and specicity scores of the five best performing two-cluster-center PVC methods in terms of DOR, at detecting heart failure.
             The \textbf{Dataset-Method} column indicates \textit{Dataset used}$/$\textit{Linkage criteria of method}$/$\textit{Number of cluster centers}.}
    \label{tab:pvc_hf_dor_sens_spec_dist}
\end{table*}

From figure \ref{fig:pvc_hf_dor_sens_spec_dist}a one can see that the DOR scores are substantially higher for PVC methods evaluated at two cluster centers to predict heart failure, 
than they are for the corresponding TSC methods. 
The scatterplot in figure \ref{fig:pvc_hf_dor_sens_spec_dist}b also shows that their exist multiple methods with both sensitivity and specificity above $0.6$ for the same PVC methods.
The exact metrics for the top performing PVC methods at predicting heart failure are given in table \ref{tab:pvc_hf_dor_sens_spec_dist}.
Common to the three highest performing PVC methods is that they all use the dataset that is a combination of peak systolic GLS values and EF values.
The highest DOR recorded is acheived when using the Ward linkage criteria, but it is not given that this is the ''best'' method.
The \textit{gls-EF/complete/2} method acheives a specificity score that is nine points higher at the cost of the sensitivity being six points lower, 
and it also has the highest overall accuracy of all the PVC methods by a small margin of one point. 
To get a better idea of how the different cluster methods perform at identifying heart failure, a scatterplot of the clusters is depicted in figure 
\ref{fig:scatter_gls_ef_hf_cluster_assignments}. \bigskip

\begin{figure}[htb]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{results/scatter_gls_EF_hf.png}
        \caption{Heart failure.}
        \label{fig:scatter_gls_ef_hf}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{results/scatter_gls_EF_ward2.png}
        \caption{\textit{Ward/2} cluster assignments.}
        \label{fig:scatter_gls_ef_ward2}
    \end{subfigure}\\
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{results/scatter_gls_EF_complete2.png}
        \caption{\textit{Complete/2} cluster assignments.}
        \label{fig:scatter_gls_ef_complete2}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{results/scatter_gls_EF_average2.png}
        \caption{\textit{Average/2} cluster assignments.}
        \label{fig:scatter_gls_ef_average2}
    \end{subfigure}
    \caption{Scatterplot of peak GLS values in each view. Colors in the of the different dots are given by heart failure diagnosis, and cluster assignments of 
             ward/2, complete/2 and average/2 methods. Numbers are not included on the axes because the point of the figure is to illustrate the separability 
             of clusters, and heart failure.}
             \label{fig:scatter_gls_ef_hf_cluster_assignments}
\end{figure}

In figure \ref{fig:scatter_gls_ef_hf_cluster_assignments} scatterplots patients are plotted with the dimensions: 4-chamber peak systolic GLS, 2-chamber peak systolic GLS and EF. 
The colors of the points correspond to wheather the patient has heart failure or not, and which cluster the points belong to.
The plots are actually a lower dimensional projection of the GLS-EF peak-value dataset. 
This particular projection was chosen as it was found to be the projection where heart failure patients were as separable as possible. 
From plots \ref{fig:scatter_gls_ef_hf_cluster_assignments}b-d one can see that the clusters are fairly separable, 
heart failure on the other hand is not as easy to separate in these dimensions as can be seen in plot \ref{fig:scatter_gls_ef_average2}. 
\textit{Ward/2} and \textit{Complete/2} can in some sense be considered as binary classifiers where values under a certain threshold are categorized as heart failure.
The \textit{ward/2} method has the highest threshold for what is considered heart failure, and \textit{complete/2} has the lowest, 
which explains their difference in sensitivity and specificity score. 
From figure \ref{fig:pvc_hf_ari} one can see that the many of the ARI of PVC methods for classifying heart failure are close to zero, but substantially more of the methods score above zero in ARI
than the TSC methods, as can be seen by a comparison of figure \ref{fig:tsc_hf_ari} and \ref{fig:pvc_hf_ari}. Table \ref{tab:pvc_hf_ari} shows that the three highest ARIs are attained by the same
three methods that acheived the highest DORs. This means that there are most likely no methods evaluated at a higher number of cluster centers that will outperform \textit{ward/2},
or \textit{complete/2} at classifying heart failure. In addition, the conclusion will be that \textit{complete/2} is the best performing PVC method when classifying heart failure, 
since it has the highest overall accuracy (76$\%$), highest ARI (0.27), and second highest DOR (10.85). 

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvc_hf_ari.png}
    \input{results/pvc_hf_ari.pgf}
    \caption{Distribution plot of ARI of all PVC methods evaluated at $\{2,9\}$ cluster centers when applied to classify heart failure.}
    \label{fig:pvc_hf_ari}
\end{figure}

\begin{table*}[htb]
    \centering
    \ra{1.3}
    \begin{tabular}{lr}
        \toprule
        Dataset-Method    &  ARI \\
        \midrule
        gls-EF/complete/2 & 0.27 \\
        gls-EF/ward/2     & 0.24 \\
        gls-EF/average/2  & 0.24 \\
        rls-EF/complete/2 & 0.21 \\
        gls-EF/complete/3 & 0.21 \\
        \bottomrule
    \end{tabular}
    \caption{The five highest ARI scores attained when applying PVC for detecting heart failure.
             The \textbf{Dataset-Method} column indicates \textit{Dataset used}$/$\textit{Linkage criteria of method}$/$\textit{Number of cluster centers}.}
    \label{tab:pvc_hf_ari}
\end{table*}

\newpage 

\subsection{Deep Neural Network}

From the distribution plot in figure \ref{fig:dl_hf_dor_sens_spec_dist}a one can see that the most frequent DOR by the NN models is zero when training them to predict heart failure.
In the scatterplot in figure \ref{fig:dl_hf_dor_sens_spec_dist}b one can see that sensitivity scores vary between $0.15$ and $0.65$, and the specificity scores vary between $0$ and $0.68$.
The highest DOR of $1.36$ is attained by using only the GLS curve from the 4-chamber view as input, as can be seen from table \ref{tab:dl_hf_dor_sens_spec_dist}.
In fact the five highest DORs attained by NN models trained to classify heart failure are acheived using only curves from a single view as input.
There does not seem to be a particular view that is favored, as 4-chamber view, 2-chamber view and apical-view are are all found in the NN variations in table \ref{tab:dl_hf_dor_sens_spec_dist}.
The overall accuracy of the model variations are also fairly low, $0.54$ being the highest accuracy acheived.
Since the heart failure dataset is fairly evenly distribution (recall figure \ref{fig:hf_ind_dist}) an accuracy of $0.54$ is not much better than what could be acheived 
by randomly guessing the label.

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/dl_hf_dor_sens_spec_dist.png}
    \input{results/dl_hf_dor_sens_spec_dist.pgf}
    \caption{(a) Distribution plot of DOR of all NN models evaluated at two cluster centers when trained to predict heart failure.
             (b) Scatter plot of the same models sensitivity-, and specificity-scores.}
    \label{fig:dl_hf_dor_sens_spec_dist}
\end{figure}

\begin{table}
    \centering
    \ra{1.3}
    \begin{tabular}{lrrrr}
        \toprule
        Dataset-Model         &  Accuracy &  Sensitivity &  Specificity &  DOR \\
        \midrule
        gls/4CH/upsampled     &      0.54 &         0.46 &         0.61 & 1.36 \\
        rls/APLAX/regular     &      0.53 &         0.48 &         0.58 & 1.30 \\
        rls/4CH/regular       &      0.52 &         0.36 &         0.68 & 1.20 \\
        gls/APLAX/downsampled &      0.52 &         0.63 &         0.40 & 1.15 \\
        gls/2CH/downsampled   &      0.51 &         0.61 &         0.40 & 1.03 \\
        \bottomrule
    \end{tabular}
    \caption{The accuracy, DOR, sensitivity and specicity scores of the five best performing variations of the NN in terms of DOR, at detecting heart failure.
             The \textbf{Dataset-Method} column indicates \textit{Dataset used}$/$\textit{View used}$/$\textit{Whether curve has been upsampled, downsampled or is regular}.}
    \label{tab:dl_hf_dor_sens_spec_dist}
\end{table}

\newpage

\subsection{Peak-value Classifiers}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvmlc_hf_dor_sens_spec_dist.png}
    \input{results/pvmlc_hf_dor_sens_spec_dist.pgf}
    \caption{Distribution of DOR, sensitivity and specificity for the different peak-value classifiers trained to predict heart failure.}
    \label{fig:pvmlc_hf_dor_sens_spec_dis}
\end{figure}

\subsection{Comparisons}

\newpage

\section{Case Study: Patient Diagnosis}

\subsection{Time-series Clustering}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc_ind_dor_sens_spec_dist.png}
    \input{results/tsc_ind_dor_sens_spec_dist.pgf}
    \caption{Distribution of DOR, sensitivity and specificity for the different TSC methods when classifying patient diagnosis.}
    \label{fig:tsc_ind_dor_sens_spec_dist}
\end{figure}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc-ind-ari.png}
    \input{results/tsc_ind_ari.pgf}
    \caption{ARI distribution of TSC methods when classifying patient diagnoses.}
    \label{fig:tsc_ind_ari}
\end{figure}

\newpage

\subsection{Peak-value Clustering}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvc_ind_dor_sens_spec_dist.png}
    \input{results/pvc_ind_dor_sens_spec_dist.pgf}
    \caption{Distribution of DOR, sensitivity and specificity for the different PVC methods when classifying patient diagnosis.}
    \label{fig:pvc_ind_dor_sens_spec_dist}
\end{figure}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvc-ind-ari.png}
    \input{results/pvc_ind_ari.pgf}
    \caption{ARI distribution of PVC methods when classifying patient diagnoses.}
    \label{fig:pvc_ind_ari}
\end{figure}

\newpage

\subsection{Deep Neural Network}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/dl_ind_dor_sens_spec_dist.png}
    \input{results/dl_ind_dor_sens_spec_dist.pgf}
    \caption{Distribution of DOR, sensitivity and specificity for the NN-variations trained to predict patient diagnosis.}
    \label{fig:dl_ind_dor_sens_spec_dist}
\end{figure}

\newpage

\subsection{Peak-value Classifiers}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/pvmlc_ind_dor_sens_spec_dist.png}
    \input{results/pvmlc_ind_dor_sens_spec_dist.pgf}
    \caption{Distribution of DOR, sensitivity and specificity for the different peak-value classifiers trained to predict patient diagnosis.}
    \label{fig:pvmlc_ind_dor_sens_spec_dist}
\end{figure}

\newpage

\subsection{Comparisons}

\newpage

\section{Case Study: Segment Indication}

\subsection{Time-series Clustering}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc_segm_ind_dor_sens_spec_dist.png}
    \caption{Distribution of DOR, sensitivity and specificity for the different TSC methods when classifying left ventrice segment indication.}
    \label{fig:tsc_segm_ind_dor_sens_spec_dist}
\end{figure}

\begin{figure}[htb]
    \centering
    % \includegraphics[width=\textwidth]{results/tsc_segm_ind_ari.png}
    \input{results/tsc_segm_ind_ari.pgf}
    \caption{ARI distribution of TSC methods when classifying classifying left ventrice segment indication.}
    \label{fig:tsc_segm_ind_ari}
\end{figure}

\newpage

\subsection{Deep Neural Network}

\begin{table}[htb]
    \centering
    \begin{tabular}{lrrrr}
        \toprule
        {}          &  Accuracy &  Sensitivity &  Specificity &  DOR \\
        Method      &           &              &              &      \\
        \midrule
        regular     &      0.74 &         0.80 &         0.68 & 8.65 \\
        downsampled &      0.74 &         0.74 &         0.75 & 8.38 \\
        upsampled   &      0.65 &         0.55 &         0.73 & 3.36 \\
        \bottomrule
    \end{tabular}
    \caption{Evaluation metrics of the NN for classifying the binary indication of individual segments in the left ventricle.}
    \label{tab:NN_segm_ind_perf}
\end{table}

\subsection{Comparisons}

