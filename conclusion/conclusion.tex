\chapter{Conclusion} \label{chap:conclusion}

The main objective of this thesis, as stated in section \ref{sec:objective} have been explore whether a machine learning model can predict three target variables using longitudinal strain as input. The three target variables being heart failure among patients, diseased patients versus control patients and abnormal behaviour of individual left ventricle segments. The main objective is followed by two sub-objectives that decided the direction and scope of the thesis: Which type of machine learning model will perform best, a supervised or unsupervised learning model, and what type of longitudinal strain data will yield the best performance for the machine learning models, the longitudinal strain curves of a segment or peak systolic longitudinal strain values in combination with \acrshort{ef}. \bigskip

A dataset of 199 patients was used to fulfill these objectives. The models that used combinations of \acrshort{gls}, and \acrshort{rls} curves from different views were a \acrshort{tsc} model and an \acrshort{ann}, which were tested to classify heart failure among patients, patient diagnosis and whether individual left ventricle segments were acting abnormally. In addition to varying the dataset used with these models different forms of preprocessing was tested for both models, and different linkages were tested for the \acrshort{tsc} model. The models that used peak systolic strain values were a \acrshort{pvc} model, and a 11 different \acrshort{pvsc}, they were only applied to identify heart failure among patients, and patient diagnosis. To assess the performance of the supervised models accuracy, sensitivity, specificity and \acrshort{dor} were used as evaluation metrics. To evaluate the unsupervised models the same metrics were used as for the supervised models, in addition to using the \acrshort{ari} to determine whether clustering models evaluated at a number of cluster centers greater than two could provide better performance than models evaluated at two cluster centers. When making a choice as to which model variation performed best within their respective model groups, and which model performed best overall the models were sorted in descending order of the \acrshort{dor} score they attained, the models which attained the highest \acrshort{dor} and accuracy while at the same time maintaining a balanced relationship of sensitivity and specificity were then chosen as the best performing models. For the clustering models, an additional evaluation was done with respect to \acrshort{ari}. If there were clustering models evaluated at a number of cluster centers greater than two that attained an \acrshort{ari} greater than the best performing two-cluster-center model, an attempt was made to visualize the result. Further, it was evaluated whether combining the clusters of the model with more than two centers could yield a better performance than the two-cluster-center model. \bigskip

The overall consensus from the results are that it is possible to implement an machine learning model that uses longitudinal strain as input, and that can predict one of the three target varables. However, there was not a single model that performed best at predicting all the target variables. The model that performed best at identifying heart failure among patients was a variation of the \acrshort{pvc} model which used a combination of peak systolic \acrshort{gls} values and \acrshort{ef} as input data, used the complete linkage and was evaluated at two cluster centers. This method attained an accuracy of 0.76, sensitivity of 0.81, specificity of 0.72 and \acrshort{dor} of 10.85. However, it was found that all the models were outperformed by a simple \acrshort{ef} threshold classifier set at $45\%$, which attained an accuracy of 0.77, sensitivity of 0.86, specificity of 0.69 and \acrshort{dor} of 13.48. This result is surprising since \acrshort{ef} was a parameter in the \acrshort{pvc} and \acrshort{pvsc} models applied to predict this target variable. For the \acrshort{pvc} models this indicates that the addition of longitudinal strain values add more noise than information, at least for a dataset of 199 objects. For the \acrshort{pvsc} models this indicates that there is a lot of potential that is not used, and that further work should be done on optimizing the hyperparameters of the \acrshort{pvsc} models. The model that performed best at predicting patient diagnosis was one of the \acrshort{pvsc} models that used the \acrshort{knn} classifier trained on a combination of peak systolic \acrshort{gls}, and \acrshort{rls} values. It attained an accuracy of 0.93, a sensitivity of 0.95, a specificity of 0.82 and a \acrshort{dor} of 84.53. In the segment indication case study, the \acrshort{ann} that downsampled all the individual \acrshort{rls} curves to the lowest sample rate of all the curves was chosen as the best model. That model attained an accuracy of 0.74, sensitivity of 0.74, specificity of 0.75 and \acrshort{dor} of 8.38. \bigskip

It was found that \acrshort{pvc}, and \acrshort{pvsc} models that used a combination of peak strain values and \acrshort{ef} generally performed better at predicting heart failure than variations that used peak strain values alone. The \acrshort{ann} was not able to generalize the features of healthy patients in the patient diagnosis case study at all, and did not perform particularily well in the heart failure case study either. It is the authors opinion that this is because the architecture of the \acrshort{ann} is to complex to be trained solely on a dataset of 199 patients. This conclusion was drawn based on the fact that the \acrshort{ann} had between 40 and 80 thousand trainable depending on how many curves were used as input. This statement is also supported by the fact that the \acrshort{ann} performed significantly better, when applied to classify single curves on a dataset of size 3600 curves. The variations of \acrshort{tsc} models that used no preprocessing performed better in general than the variations that used normalization, z-normalization or scaling, meaning that purely shape-based \acrshort{tsc} is not optimal for clustering left ventricle strain curves for diagnosing patients.

\section{Limitations}

The biggest limitation encountered was the number of objects in the dataset. This is particularily evident in the performance of the \acrshort{ann} in the heart failure, and patient diagnosis case studies. It performed much better in the segment indication case study, as the dimensionality was reduced to only a single time series as input, and the number of objects was multiplied by 18. So it is impossible to make any conclusive statements as to whether any specific machine learning model is inappropriate for the applications in this work, because the dataset is too small. 

\section{Future Work}

It is this section further improvements that can be done on the \acrshort{tsc} models, \acrshort{ann} models, and \acrshort{pvsc} models are discussed. 

\subsection*{Dimensionality Reduction in Time-series Clustering}

This work focused on feature selection by testing different subsets of the datasets as inputs. In future work one could consider trying the approach of \cite{hf_diagnosis_ml} of using principle component analysis to reduce the dimensionality into more information-dense combinations of the input features. Additionally, one should consider the approach mentioned in the section \ref{sec:disc_tsc} of combining point-value \acrshort{ef} to the \acrshort{tsc}. This could be done by calculating the dissimilarity matrix of \acrshort{ef} values separately using a distance metric such as Euclidean distance, and adding it to the other dissimilarity matrices as if it were another curve dimension.

\subsection*{Development of an Artificial Neural Network for Segment Indication}

Given that the \acrshort{ann} performed so well at identifying the binary segment indication, it is probable that by spending more time adapting the architecture to the segment indication dataset one could achieve performances that are better than the ones attained in this piece of work. One could start with the architecture used in this assignment, and attempt to reduce the complexity of the architecture by adding pooling layers, or dropout layers. It should be tested whether using \acrshort{gru} cells could could improve the accuracy of the \acrshort{ann} as they are known to require less data than \acrshort{lstm} cells to generalize the difference between different segment labels. One should also experiment with variations of \acrshort{sgd} for training the network, such as batch gradient descent and mini-batch gradient descent. If concentrating mainly on an \acrshort{ann} solution one could also test if the resulting model is capable of dealing with segment indication when multiple classes are used. 

\subsection*{Development of Peak-value Supervised classifiers}

Recall that the \acrshort{pvsc} models performed best at predicting patient diagnosis. As mentioned in section \ref{sec:disc_pvsc}, although the \acrshort{pvsc} did not perform best at identifying heart failure in patients, the distribution of the \acrshort{dor} for the \acrshort{pvsc} models was shifted significantly higher, and centered higher than the \acrshort{dor} distribution of the \acrshort{tsc}, \acrshort{pvc} and \acrshort{ann} models. Since there was not enough time to optimize the hyperparameters of the classifiers in the \acrshort{pvsc} group, this shift in distribution indicates that there is some lost potential as to what performance these models could attain. Therefore, it is probable that by spending more time on adapting the individual classifiers to the heart failure, and patient diagnosis datasets one could produce models that yield higher scores in all evaluation metrics.